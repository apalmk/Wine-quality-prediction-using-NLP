{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML4_Task2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRCaf6Sau6B6",
        "colab_type": "text"
      },
      "source": [
        "# **AML 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqbc9T2CyQU",
        "colab_type": "text"
      },
      "source": [
        "***Teammates:***\n",
        "\n",
        "Karthik Rajaraman Iyer\n",
        "kr2859@columbia.edu\n",
        "\n",
        "Anjani Prasad Atluri\n",
        "aa4462@columbia.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gLM1FFfu2p4",
        "colab_type": "text"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvA02MIeLt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import gc\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import download\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import word_tokenize     \n",
        "import numpy as np\n",
        "from gensim import models\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import nltk     \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H6txlq8FfdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading the model\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPnSRbSMvTHy",
        "colab_type": "code",
        "outputId": "7cd959e1-4177-4a10-c677-5831f732f4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#loading the dataset\n",
        "\n",
        "#mounting drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "#data loading\n",
        "df = pd.read_csv('/content/gdrive/My Drive/Columbia Photos/winemag-data-130k-v2.csv')\n",
        "\n",
        "#subsampling the data\n",
        "df1=df.sample(frac=0.5, random_state=0)\n",
        "#df1 = df.copy()\n",
        "\n",
        "#data splitting\n",
        "y=pd.DataFrame(df1['points']).values\n",
        "X= df1.loc[:, df1.columns != 'points']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "#getting the data into required format\n",
        "\n",
        "#Append the title column data to the description column data and make a list\n",
        "nX_train= list(X_train['description'] +' '+ X_train['title'])\n",
        "nX_test = list(X_test['description'] +' '+ X_test['title'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZQU2d4Rqoha",
        "colab_type": "text"
      },
      "source": [
        "## **Just the word embeddings model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z320CeQEe1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "docs_train = [nlp(d).vector for d in nX_train]\n",
        "X_train = np.vstack(docs_train)\n",
        "\n",
        "docs_test = [nlp(d).vector for d in nX_test]\n",
        "X_test = np.vstack(docs_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qDHhWVRDmVs",
        "colab_type": "code",
        "outputId": "e7777b34-167c-466b-a873-198b4f9281b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Training a linear model on just the embeddings \n",
        "\n",
        "lr_w2v = Ridge(alpha=1).fit(X_train, y_train)\n",
        "\n",
        "print(\"testing score for word embeddings model: \",lr_w2v.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing score for word embeddings model:  0.5296116719208357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hODuJPxNshsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting un-necessary data to save RAM\n",
        "\n",
        "del [[df1,df,X,y, docs_train,docs_test,X_train,X_test,en_core_web_lg]]\n",
        "gc.collect()\n",
        "df1= pd.DataFrame()\n",
        "df= pd.DataFrame()\n",
        "X=pd.DataFrame()\n",
        "docs_train=[]\n",
        "X_train=pd.DataFrame()\n",
        "X_test=pd.DataFrame()\n",
        "docs_test=[]\n",
        "y=np.ndarray(shape=(2,2), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70uJeTtnqxw5",
        "colab_type": "text"
      },
      "source": [
        "## **Just the GLOVE model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmXXGk7Qq07x",
        "colab_type": "code",
        "outputId": "ed84c1dc-7fe7-40a7-bb3a-73f8df55dfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Loading the Glove model\n",
        "\n",
        "print(\"Loading Glove Model\")\n",
        "f = open(\"/content/gdrive/My Drive/glove.vocab.300d.txt\",'r', encoding=\"utf8\")\n",
        "model = {}\n",
        "for line in f:\n",
        "    splitLine = line.split()\n",
        "    word = splitLine[0]\n",
        "    #print(type(model))\n",
        "    model[word] = np.array([float(val) for val in splitLine[1:]])\n",
        "f.close()\n",
        "print(\"Done.\",len(model),\" words loaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 439  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-XPvbM98nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Writing the Glove avg function\n",
        "def return_avg_glove(X):\n",
        "  R = list()\n",
        "  for desc in X:\n",
        "    l = 0\n",
        "    s = np.zeros(300)\n",
        "    for word in desc.split():\n",
        "      word = word.replace(\",\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\".\",\"\").replace(\";\",\"\").lower()\n",
        "      if word in model:\n",
        "        s += model[word]\n",
        "        l += 1\n",
        "      else:\n",
        "        pass\n",
        "        #print(word)\n",
        "    s /= l\n",
        "    R.append(s)\n",
        "  return R\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5a_9iVj9mGI",
        "colab_type": "code",
        "outputId": "6bf4f693-417e-4af4-fcf0-fb44980b1e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vect = Pipeline([(\"embedding\",FunctionTransformer(return_avg_glove))])\n",
        "X_train = vect.fit_transform(nX_train)\n",
        "X_test = vect.transform(nX_test)\n",
        "clf = LinearRegression().fit(X_train, y_train)\n",
        "print(\"testing score for Glove Averaged Model: \",clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing score for Glove Averaged Model:  0.4451769822978259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxxi-SkIlp-",
        "colab_type": "text"
      },
      "source": [
        "As we can see with just the pre-trained embeddings or the GLOVE model we were not able to get any improvement over the previous models. So we will try adding the GLOVE model with the bag of words model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buX9FriKJItG",
        "colab_type": "text"
      },
      "source": [
        "### **Bag of words model + GLOVE model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzW29hKTJOLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making a Stemming function from nltk reference: https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn\n",
        "stemmer = EnglishStemmer()\n",
        "analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))\n",
        "\n",
        "#Encodings of the bag of words model that performed best form the previous task\n",
        "\n",
        "vect = make_pipeline(CountVectorizer(min_df=3, stop_words=\"english\",lowercase=True, analyzer=stemmed_words, token_pattern=r\"\\b\\w[\\wâ€™]+\\b\"),FunctionTransformer(lambda x:x.todense()))\n",
        "teXt_train = vect.fit_transform(nX_train)\n",
        "teXt_test = vect.transform(nX_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMpR-Prg-nl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting data to save RAM\n",
        "del [[nX_train,nX_test]]\n",
        "gc.collect()\n",
        "nX_train=[]\n",
        "nX_test=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWHeBcNHl_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Concatenating both the data\n",
        "\n",
        "X_tr = np.concatenate((X_train, teXt_train),axis=1)\n",
        "\n",
        "#deleting data to save RAM\n",
        "del [[teXt_train,X_train]]\n",
        "gc.collect()\n",
        "teXt_train=[]\n",
        "X_train=np.ndarray(shape=(2,2), dtype=float)\n",
        "\n",
        "X_te = np.concatenate((X_test, teXt_test),axis=1)\n",
        "\n",
        "#deleting data to save RAM\n",
        "del [[teXt_test,X_test]]\n",
        "gc.collect()\n",
        "teXt_test=[]\n",
        "X_test=np.ndarray(shape=(2,2), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrHaGEqGMV32",
        "colab_type": "code",
        "outputId": "e95bd4a7-7c3f-44e9-e5a6-bef3e7b1b500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Training a linear model on just the embeddings \n",
        "\n",
        "lr_w2v = Ridge(alpha=20).fit(X_tr, y_train)\n",
        "\n",
        "print(\"testing score for word embeddings model: \",lr_w2v.score(X_te, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing score for word embeddings model:  0.7466024942371853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLB5nAJyC6AB",
        "colab_type": "text"
      },
      "source": [
        "Hence we found that the GLOVE model alone couldn't perform better than models we got from the task 1. The GLOVE model with the bag of words model performed closer to the model we obtained in the task 1.4"
      ]
    }
  ]
}